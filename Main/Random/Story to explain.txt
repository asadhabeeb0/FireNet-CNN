We have been given an assignment of Artificial inntelligence. Where there was a reference paper. This paper include working on Fire and smoke detection using a lightweight model for Real world Internet of thing applications. The puposed model architecture was in such a way, that it contain 14 layers First convolutional 2D layer have bias of 16 kernel size was 3 y 3 bias of 16 which has successor layer of average pooling 2D next layer was dropout of 0.5 next layer was second convolutional 2D layer same as old one having only difference of bias , this time bias was 32, and then same average pooling asnd same dropout layer, then there was 3rd convolutional 2D layerwhich has bias of 64 but same pooling and dropout layers. Then flatten layer was used , then dense layer of bias 256 having dropout of 0.2 and then dense layer of bias of 128 with same dropout and last layer of bias 2 with softmax activation function. The link of the reference paper is https://arxiv.org/abs/1905.11922 This model was chceked on two dataset first was predined foggia dataset having vast data of videos any one can make its one datset from these fire and nonfire videos. The author prepared its own dataset from these videos using frames. Many people were using this foggia dataset so author designed a model to have mininmum trainable features but maximum accuracy, When own dataset was prepared it gave new scope, but the purposed model was good at both dataset. Other people were also working on foggia daatset they started to work on this new FireNet dataset. Author maped different its model on both datset and got good results. Model was working well, when training and validation accuracy was mapped for 100 epochs. It gave accuracy linearly increasing , mean model was learning well, the accuracy of author model against foggia dataset was amazing yet charming against the FireNet dataset, similarly was precision and recall. We were assigned task for reducing trainable feature while increasing accuracy, recall , percision at same time. I and my group mate inferenced from that we prepared some models written in last cell of the notebook, we started working on it , we were applying differentn epochs for training of same model and checking. We were changing dropouts, changing pooling, removing dropouts and many other techniques. 
Then we proceded to next version of this paper, we also were impressed by some small models. Then we came to know about architecture of second model there was not major changes. There was chabge of bias from 16 to 15 in first convo2d and large in next 2 convo2D, the activation function was changed a bit. 

We were convinced by the author comments "model is designed to have outputs in the form of ‘one-hot’ encoding i.e. there are
2 outputs and only one of them is high for any given test image (fire/non-fire). The Softmax activation will ensure that
the sum of the assigned probabilities for the 2 output classes is equal to unity, and therefore, in order to increase the
estimated probability of a particular class, the model is forced to correspondingly decrease the estimated probabilities
of the other classes (and vice-versa). Therefore, using this approach, there is a clearer fire/non-fire classification. If a
Sigmoid was used, there would be only 1 output, which would have shown the probability that the given image was
fire/non-fire. Lastly, since in binary classification both Sigmoid and Softmax functions are essentially the same, there
is no ‘performance degradation’ using Softmax over Sigmoid" for activation function. We made inferences from there that there is mathematical relationship in the changing of the layer. Since author mapped its accuracy against different other models in grapgh and table. We approached to these models specifically 'Saponara' and 'Elenashi' model. We stopped working on first version of FireNet but rather made matrices for second models relation we came to know that we have to select less top convo2D layer so most suitable option was use of 14 bias. Since it is first layer. We inferred that if we used 12 as first layer then we will have to calculate relation of third to second layer and found doubling of increment in bias similar for 13 and 14 and first layer. We found some models written below. We were learned from bias 12 as first layer. We made calculations and selected dome models for 13 and 14 as base. Then we were chceking it aginst different dropouta and activation function. Then we were running the models for 50 epochs. We were notcing training accuracy, that it si increasing or not. We were also notcing validation accuracy, that it is going with training accurcay or getting worse. We were changing activation function, dense layers, droput of FireNet version 2 to get best results for training versus validation accuracy. When we got good sequence for 14 as base convo2D layer we run all 14's for 50 epochs. e and i got significant testing accuracy. When compiled for 70 epochs a got 74%, b got 89%, c got 85, d got 70, e got 91.04% testing accuracy, f got 90%, g got 84.27%, h got 80 while i got 93.46% evaluation accuracy against test data. We notice e and i. We done 90 epochs for next phase now. Now we installed weights for our training saving and loading model when necessary. For 90 epcohs accuracies of all were down but b maintain it and increased to 92.76% accuracy against test data. Now , we noted that which model is getting highest accuracy at which points. We formed column given below. We checked b for 100 epochs it given 81.4, mean 90 epochs was its best position. Now, we extracted some base on these epochs, e , i and b were performing well so we extracted all others. We changed batch size form 32 to 48. But none of e,i, b was performing well. Now we start using weights, we epoch the model to 30 or 40 epoch save the weight load it again when to epoch for 70,80,90. While using weights we noted some things, some models were performing well at sudden position but not good at the edges of this postions. We started removing second dense layer and found positive results.We noted that i was outstanding when first epoch was 10 and second epoch was 50, it give accuracy of 95.63% on evaluation against test data with two dense layers. Similarly e for 10 as first and 50 epoch as second got 93%. i on 10 as first and 70 as second got 94.95 accuracy. When removed second dense layer, we also run the e,i and b for some linear epochs in which we got our result. When e was run for 10,20,30,40,50 epoch it gave accuracy of 94.26%. Now, we tried four models, one was i with 10,50 it gave 95.63% elite accuracy, e was run linearly it gave 94.26% on 10,20,30,40,50th. Here we found ou model which is presented below.

Our model was working well, providing nice accuracy for test data, good prediction and linear curve. Model is generalizing the things well, having train data augmentation. Since trainable features are decreased and accuracy minorly achieved, model is performing good at new data, learning data is already very small.But when epochs are increased from 50, model is not performing well, model is perhap remembering the train data instead of generaalization. So improvements are needed there which would include normalization, enhancing hyper peramters, changing train-test split.
